{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXmY9E6Pd7iIf60bOxtQ+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya-israni/IEEE---ML-AI/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiAzTXetzTRe",
        "outputId": "2464e80b-4e0b-420c-df80-40b1a05f625d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# %matplotline inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, testing_data = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(f'Training Data Shape: {training_data[0].shape}')\n",
        "print(f'Testing Dta Shape: {testing_data[0].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdZU2iH1UAi",
        "outputId": "dedd1b54-dfaa-43ed-93cd-c890b96b0313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Training Data Shape: (60000, 28, 28)\n",
            "Testing Dta Shape: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = np.random.randint(low=0,high=training_data[0].shape[0],size=1,dtype=int) #this is just looking at some random index\n",
        "random_example = np.squeeze(training_data[0][random_index],axis=0)  #axis=0 means i want to take out the first index (zero)\n",
        "#0 in first cell for x which is index of random thing, 1 in second for y which is our labels\n",
        "\n",
        "plt.imshow(random_example)\n",
        "print(f'Image Label: {training_data[1][random_index][0]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "wI-4dHQT2ZJx",
        "outputId": "0f7e1ac9-7cfa-496e-9b0b-84298c564d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Label: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#supervised learning x --> y (f(x)) -- basically it's predicting an output with x, we write the --> to get to y (nueral networks approximates)\n",
        "train_x = training_data[0] / 255.0    #/ by 255 to scale the numbers down so runtime is faster (easier to work w smaller numbers), 0-255 is the pixel values for images\n",
        "train_y = training_data[1]            #y is for our labels 0-9 (digits) so we don't want to scale this bc then model will not be able to detect the number\n",
        "\n",
        "test_X = testing_data[0] / 255.0\n",
        "test_y = testing_data[1]"
      ],
      "metadata": {
        "id": "L52r1gHy3-YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of X: {train_x.shape}')\n",
        "print(f'Shape of Y: {train_y.shape}') #after , is 1 python doesn't put\n",
        "\n",
        "#1 after 60000 bc you are prediciting 1 thing and this is scalar (label is just a vector, which is one column so like one vertical down matrix)\n",
        "#1 after 60000 bc there is only one column for the labels\n",
        "#y is like 3[1 4 5] (pretend there is a enter between each digit), inside the [] is the labels you are getting\n",
        "#these are categorical variables (the labels) we don't care abt the values so they view it w the 0 1 shit so the model can't tell what's bigger and take that into account (makes it bins)\n",
        "#28 for shape of x bc it is not scalar (28 is the size of the images, 2D)\n",
        "#60000 is the number of data you have (images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hexizgHk53Kl",
        "outputId": "861eb69a-f1a4-42dc-85db-46f725d87633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (60000, 28, 28)\n",
            "Shape of Y: (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = keras.utils.to_categorical(train_y,num_classes=10) #10 bc 0-9, how many digits we are trying to predict\n",
        "test_y = keras.utils.to_categorical(train_y,num_classes=10)\n",
        "#this makes y 1 0 bc we want it to be since we have 10 digits?\n",
        "print(f'{train_y.shape}')"
      ],
      "metadata": {
        "id": "SGdJEYUk7yAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719aa937-c6cb-4f68-d534-3913417b0aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for nueral netwokrs (which are functions) we do a weighted summation and add a bias to it bc nature has bias so our function should\n",
        "#we give it x and w for the summation, x is different inputs and w is it's weight(or parameters) (we have to find them) (weight like importance i think)\n",
        "#activation functions introduce the non linear relationships to our ML models bc functions are like never linear fo predicting stuff\n",
        "  #one common activation function is ReLU\n",
        "\n",
        "#building model, sequential tells keras it is fully connected bc every output in each layer goes to the next layer\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28))) #always add an input layer so keras knows what to expect (like what shape)\n",
        "#can only take in vector so make matrix vector, flattening rows and columns by stacking them; vector=28*28 = 784 (this will be our vector since when you stack the images you do 28*28 which is our pixel values)\n",
        "#(each matrix is 1 image)\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=7,activation='relu')) #dense bc flattened it, these 4 are hidden layers\n",
        "model.add(Dense(units=50,activation='relu'))\n",
        "model.add(Dense(units=20,activation='relu'))\n",
        "model.add(Dense(units=13,activation='relu')) #every nueron uses all these units bc in each layer we're doing the summation thing w 13 units and so on\n",
        "model.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "#output layer, 10 bc 10 digits so 10 classes, softmax gives us probabilites, which we want our last layer to be (does this by e^x(layer)/summation e^x (e^x(layer) for all layers added))\n",
        "#hidden layers are downstream, output layer is the last layer (middle hidden layers normally 50-100)\n",
        "#7328 is found by adding how many weights/params we have\n",
        "#for dense 11 we have 50 neurons and only 7 weights to take in so its 400 (it goes after each other like that), 7 nuerons and 784 weights/params to take it, etc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWgHkJ-U8bI5",
        "outputId": "6a0bbfad-5e45-46b0-b41b-25b626294e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 5495      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                400       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 13)                273       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                140       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7328 (28.62 KB)\n",
            "Trainable params: 7328 (28.62 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we randomly set our weights (ex. 50, 20), but we want to find them\n",
        "#lost function tells us how shitty our model is based on weights, want to minimize this\n",
        "#we want to find the set of weights through the like bottom of the lost function(like imagine that graph when you get near the bottom (graph is like downward parabola from top to bottom))\n",
        "#we use the chain rule to find the weights in relation to the lost function (derivative tells us how steep it is from hill)\n",
        "#after finding the weight use gradient descent to update this (the weights) and optimize the function (for this function we set an alpha that shouldn't be too big or small bc it's the steps you take down the hill(lost function)) - we are taking a step down the most steep part (small steps takes too long and big ones overshoots the bottom)\n",
        "\n",
        "loss_function = 'categorical_crossentropy' #i think we want it to be higher not lower? penalty thing\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01) #runs gradient descent on a randomly selected point/group of points so doesn't take as long (learning rate is alpha)\n",
        "metrics = ['accuracy']\n",
        "model.compile(optimizer=optimizer,loss=loss_function,metrics=metrics)\n",
        "\n",
        "history = model.fit(x=train_x,y=train_y,batch_size=32,epochs=50,shuffle=True) #epochs is how many steps im taking of gradient descent we do, we shuffle the data so the model doesn't memorize the order of the images (each  point is an image)\n",
        "#batch_size is divinding the data into batch sizes so you don't have to throw the entire data in bc that would take forever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWJ9fCv2B5vB",
        "outputId": "9aa7acfe-6e9b-4272-e802-9665b56a88ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 19s 7ms/step - loss: 1.4453 - accuracy: 0.4921\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5040 - accuracy: 0.8476\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3874 - accuracy: 0.8851\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3479 - accuracy: 0.8965\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3280 - accuracy: 0.9023\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3129 - accuracy: 0.9076\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3017 - accuracy: 0.9094\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2927 - accuracy: 0.9138\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2856 - accuracy: 0.9139\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2782 - accuracy: 0.9170\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2732 - accuracy: 0.9184\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2692 - accuracy: 0.9184\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2652 - accuracy: 0.9200\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2608 - accuracy: 0.9213\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2563 - accuracy: 0.9234\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2507 - accuracy: 0.9238\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2435 - accuracy: 0.9278\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2375 - accuracy: 0.9296\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2320 - accuracy: 0.9307\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2267 - accuracy: 0.9324\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2235 - accuracy: 0.9329\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2197 - accuracy: 0.9354\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2169 - accuracy: 0.9349\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2141 - accuracy: 0.9357\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2117 - accuracy: 0.9366\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2091 - accuracy: 0.9377\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2071 - accuracy: 0.9379\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2056 - accuracy: 0.9385\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2036 - accuracy: 0.9391\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2018 - accuracy: 0.9397\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1995 - accuracy: 0.9401\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1982 - accuracy: 0.9408\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1965 - accuracy: 0.9408\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1945 - accuracy: 0.9414\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1940 - accuracy: 0.9414\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1927 - accuracy: 0.9415\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1916 - accuracy: 0.9422\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1904 - accuracy: 0.9426\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1891 - accuracy: 0.9429\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1877 - accuracy: 0.9429\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1862 - accuracy: 0.9435\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1855 - accuracy: 0.9442\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1844 - accuracy: 0.9445\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1832 - accuracy: 0.9448\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1829 - accuracy: 0.9449\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1819 - accuracy: 0.9449\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1803 - accuracy: 0.9450\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1803 - accuracy: 0.9460\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1791 - accuracy: 0.9453\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1785 - accuracy: 0.9457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=train_x,y=train_y,batch_size=32) #had to make it lowercase x not X ??"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD6xkmumHXhv",
        "outputId": "e6035f8a-bdef-49d2-84cb-9f3345340bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1752 - accuracy: 0.9466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1752495914697647, 0.9466000199317932]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = np.random.randint(low=0,high=training_data[0].shape[0],size=1,dtype=int)\n",
        "random_example = np.squeeze(training_data[0][random_index],axis=0)\n",
        "\n",
        "plt.imshow(random_example)\n",
        "print(f'Image Label: {training_data[1][random_index][0]}')\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "7FAqv7toIhLe",
        "outputId": "d9937cd6-a3da-4dc4-a966-dcb3f8a3f912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Label: 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcNElEQVR4nO3df3RU9f3n8dcQkhE0GRpCfkmgAUWsQNxSiFkUY0kJ6R4WhG8PqP0ueFz8SoNboFZPehSEdjct7rGuLJU9+61Q94go+xVYXUsPBhPWNqElylJamyVsWkIhQdnNTAgQQvLZP1inDiTiHWbyzo/n45x7Dpm5n9y31zk8ucxw43POOQEA0MuGWA8AABicCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAx1HqAK3V1denkyZNKTk6Wz+ezHgcA4JFzTq2trcrOztaQIT1f5/S5AJ08eVI5OTnWYwAArlNjY6NGjx7d4/N9LkDJycmSpLv1TQ1VovE0AACvLqlD7+ud8O/nPYlbgDZt2qTnnntOTU1NysvL08aNGzV9+vRrrvv0r92GKlFDfQQIAPqd/3+H0Wu9jRKXDyG8/vrrWr16tdauXasPPvhAeXl5Ki4u1unTp+NxOABAPxSXAD3//PNatmyZHn74YX3lK1/R5s2bNXz4cL388svxOBwAoB+KeYAuXryo2tpaFRUV/e0gQ4aoqKhI1dXVV+3f3t6uUCgUsQEABr6YB+iTTz5RZ2enMjIyIh7PyMhQU1PTVfuXl5crEAiENz4BBwCDg/k/RC0rK1MwGAxvjY2N1iMBAHpBzD8Fl5aWpoSEBDU3N0c83tzcrMzMzKv29/v98vv9sR4DANDHxfwKKCkpSVOnTlVFRUX4sa6uLlVUVKigoCDWhwMA9FNx+XdAq1ev1pIlS/S1r31N06dP1wsvvKC2tjY9/PDD8TgcAKAfikuAFi1apI8//lhr1qxRU1OT7rzzTu3Zs+eqDyYAAAYvn3POWQ/xWaFQSIFAQIWax50QAKAfuuQ6VKndCgaDSklJ6XE/80/BAQAGJwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBiqPUAwLUkjAhEsSghqmPVPTPB85qupC7Pa3zO53lNX3djg/dzPvo//d7zmq7WVs9r0DdxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpNCQG26Iat25oime1zT+XafnNf+9cKPnNRMSo/tvkt71vCLB5/3PcZ3O+w1MB6L/8q8zPa/5Dxv/zvOa9E2/8bwG8ccVEADABAECAJiIeYCeffZZ+Xy+iG3ixImxPgwAoJ+Ly3tAd9xxh959929/lz50KG81AQAixaUMQ4cOVWam9zcXAQCDR1zeAzp69Kiys7M1btw4PfTQQzp+/HiP+7a3tysUCkVsAICBL+YBys/P19atW7Vnzx699NJLamho0D333KPWHn6Oe3l5uQKBQHjLycmJ9UgAgD4o5gEqKSnRt771LU2ZMkXFxcV655131NLSojfeeKPb/cvKyhQMBsNbY2NjrEcCAPRBcf90wIgRIzRhwgTV19d3+7zf75ff74/3GACAPibu/w7o7NmzOnbsmLKysuJ9KABAPxLzAD3xxBOqqqrSn//8Z/3mN7/R/fffr4SEBD3wwAOxPhQAoB+L+V/BnThxQg888IDOnDmjUaNG6e6771ZNTY1GjRoV60MBAPqxmAdo+/btsf6WiLNz3/B+U1FJ2rd5c4wn6Um0NxZFX/f3yU3eFz3+Xz0veaPyPu/HkdT5h7qo1uGL4V5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJuP9AOvR9iWcvRbVu+1nvdzhv7fR+Y9FFyUc9r/nnNf/geY0kld+5M6p1Xv1ow9/3ynGidXa0z/OaZxa/7nnN4ps+9rwmqhuY/tN73tdIen3qrZ7XdLW1RXWswYgrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjwOeec9RCfFQqFFAgEVKh5GupLtB4Hn2NozmjPa9z5857XnJ0x3vOaG/ce8bxGknTr2OjWedT1Pz/qleP0pmheDw++W+15TTR30I7Wv5i/xPMa97vfx2GS/uWS61CldisYDColJaXH/bgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMDLUeAP3XpcYTvXKcYbvPeF7TFe3BBuBNQntLNK+HhvZR3g/Uizcj/V9Lhntec+vv4jDIAMUVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAkAPUuoSrEcY0LgCAgCYIEAAABOeA7R//37NnTtX2dnZ8vl82rVrV8TzzjmtWbNGWVlZGjZsmIqKinT06NFYzQsAGCA8B6itrU15eXnatGlTt89v2LBBL774ojZv3qwDBw7oxhtvVHFxsS5cuHDdwwIABg7PH0IoKSlRSUlJt8855/TCCy/o6aef1rx58yRJr7zyijIyMrRr1y4tXrz4+qYFAAwYMX0PqKGhQU1NTSoqKgo/FggElJ+fr+rq6m7XtLe3KxQKRWwAgIEvpgFqamqSJGVkZEQ8npGREX7uSuXl5QoEAuEtJycnliMBAPoo80/BlZWVKRgMhrfGxkbrkQAAvSCmAcrMzJQkNTc3Rzze3Nwcfu5Kfr9fKSkpERsAYOCLaYByc3OVmZmpioqK8GOhUEgHDhxQQUFBLA8FAOjnPH8K7uzZs6qvrw9/3dDQoEOHDik1NVVjxozRypUr9aMf/Ui33nqrcnNz9cwzzyg7O1vz58+P5dwAgH7Oc4AOHjyo++67L/z16tWrJUlLlizR1q1b9eSTT6qtrU2PPvqoWlpadPfdd2vPnj264YYbYjc1AKDf8xygwsJCOed6fN7n82n9+vVav379dQ0GANbOZ/T8ex2un/mn4AAAgxMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMeL4bNgAMFrf85xOe11yKwxwDFVdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKICZaF93lec33R26M4kgJUayJjguGeu1YgxFXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCuAqvql3eF6z5t9u8bzG70v0vCYa/+bktKjWuQvtMZ4En8UVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRImpDb872vsifFPtB0KOLOV+Kal3pP+7wvOYbw857XtPpPC/R95qme15z6If/zPuBJA278Nuo1uGL4QoIAGCCAAEATHgO0P79+zV37lxlZ2fL5/Np165dEc8vXbpUPp8vYpszZ06s5gUADBCeA9TW1qa8vDxt2rSpx33mzJmjU6dOhbfXXnvtuoYEAAw8nj+EUFJSopKSks/dx+/3KzMzM+qhAAADX1zeA6qsrFR6erpuu+02LV++XGfOnOlx3/b2doVCoYgNADDwxTxAc+bM0SuvvKKKigr95Cc/UVVVlUpKStTZ2dnt/uXl5QoEAuEtJycn1iMBAPqgmP87oMWLF4d/PXnyZE2ZMkXjx49XZWWlZs2addX+ZWVlWr16dfjrUChEhABgEIj7x7DHjRuntLQ01dfXd/u83+9XSkpKxAYAGPjiHqATJ07ozJkzysrKivehAAD9iOe/gjt79mzE1UxDQ4MOHTqk1NRUpaamat26dVq4cKEyMzN17NgxPfnkk7rllltUXFwc08EBAP2b5wAdPHhQ9913X/jrT9+/WbJkiV566SUdPnxYv/jFL9TS0qLs7GzNnj1bP/zhD+X3+2M3NQCg3/McoMLCQjnX8x0Ef/WrX13XQLg+Xfd6v+niiRWXojrWP079hec1dw3AP4ck+Lz/TXan64rDJIPDnmO3e14zdjc3Fe2LuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMT8R3IPBr6h3k/b+ZKvel7Tvvz/eF7z7IRtntd8Y9h5z2sAK+vv/G+e1zz97x6M6ljj1vzO8xp3Kbq7yw9GXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GWkU/rpquuc1h1b+xzhMYusPHRc9r9nYPCsOk1zt39/8blTrbvL5YzwJYm3hjf/X+5olm6I61qJ7Znte03rPJ1EdazDiCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSKPQ9uVO6xFiaslfvh7Vut/tu93zGl+X9+PcO+eQ90WQJK3/ZHJU63a9fK/3RT7vSxY8XOl5zdNpR7wfKEr/ctQhz2te1ejYDzJAcQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjwOeec9RCfFQqFFAgEVKh5GupLtB6nW+v+d63nNdP8UdypsZfUtEe37i5/bOforxJ83v8ct6xxhuc1f35yguc1iX/6q+c1ktTZfDqqdV4lZKR7XvPXxbd4XuOf/bHnNZKU9oT3NZ0fHY3qWAPJJdehSu1WMBhUSkpKj/txBQQAMEGAAAAmPAWovLxc06ZNU3JystLT0zV//nzV1dVF7HPhwgWVlpZq5MiRuummm7Rw4UI1NzfHdGgAQP/nKUBVVVUqLS1VTU2N9u7dq46ODs2ePVttbW3hfVatWqW33npLO3bsUFVVlU6ePKkFCxbEfHAAQP/m6Sei7tmzJ+LrrVu3Kj09XbW1tZo5c6aCwaB+/vOfa9u2bfr61y//lM0tW7bo9ttvV01Nje66667YTQ4A6Neu6z2gYDAoSUpNTZUk1dbWqqOjQ0VFReF9Jk6cqDFjxqi6urrb79He3q5QKBSxAQAGvqgD1NXVpZUrV2rGjBmaNGmSJKmpqUlJSUkaMWJExL4ZGRlqamrq9vuUl5crEAiEt5ycnGhHAgD0I1EHqLS0VEeOHNH27duva4CysjIFg8Hw1tjYeF3fDwDQP3h6D+hTK1as0Ntvv639+/dr9OjR4cczMzN18eJFtbS0RFwFNTc3KzMzs9vv5ff75ffzLxoBYLDxdAXknNOKFSu0c+dO7du3T7m5uRHPT506VYmJiaqoqAg/VldXp+PHj6ugoCA2EwMABgRPV0ClpaXatm2bdu/ereTk5PD7OoFAQMOGDVMgENAjjzyi1atXKzU1VSkpKXr88cdVUFDAJ+AAABE8Beill16SJBUWFkY8vmXLFi1dulSS9NOf/lRDhgzRwoUL1d7eruLiYv3sZz+LybAAgIGDm5FG4eu/b7v2Tld4IrXu2jshZja2jItq3eY/3ON5jf/XyZ7X3LzN+w0rOz+O7oaaQG/jZqQAgD6NAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJqL6iaiD3Y4XijyveWJ9370bdsX56H4i7T/8j38V40m6d9MfvM+XszW68z32k99Htc6rzl45CtC3cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqRRGPlyjec1c//pvjhMEhuusyuqdRNaa2M8Sexws0+g7+MKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1Io+Gc5yWdLcE4DAIA/RdXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMCEpwCVl5dr2rRpSk5OVnp6uubPn6+6urqIfQoLC+Xz+SK2xx57LKZDAwD6P08BqqqqUmlpqWpqarR37151dHRo9uzZamtri9hv2bJlOnXqVHjbsGFDTIcGAPR/nn4i6p49eyK+3rp1q9LT01VbW6uZM2eGHx8+fLgyMzNjMyEAYEC6rveAgsHLP2Y6NTU14vFXX31VaWlpmjRpksrKynTu3Lkev0d7e7tCoVDEBgAY+DxdAX1WV1eXVq5cqRkzZmjSpEnhxx988EGNHTtW2dnZOnz4sJ566inV1dXpzTff7Pb7lJeXa926ddGOAQDop3zOORfNwuXLl+uXv/yl3n//fY0ePbrH/fbt26dZs2apvr5e48ePv+r59vZ2tbe3h78OhULKyclRoeZpqC8xmtEAAIYuuQ5VareCwaBSUlJ63C+qK6AVK1bo7bff1v79+z83PpKUn58vST0GyO/3y+/3RzMGAKAf8xQg55wef/xx7dy5U5WVlcrNzb3mmkOHDkmSsrKyohoQADAweQpQaWmptm3bpt27dys5OVlNTU2SpEAgoGHDhunYsWPatm2bvvnNb2rkyJE6fPiwVq1apZkzZ2rKlClx+Q8AAPRPnt4D8vl83T6+ZcsWLV26VI2Njfr2t7+tI0eOqK2tTTk5Obr//vv19NNPf+7fA35WKBRSIBDgPSAA6Kfi8h7QtVqVk5OjqqoqL98SADBIcS84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJodYDXMk5J0m6pA7JGQ8DAPDskjok/e338570uQC1trZKkt7XO8aTAACuR2trqwKBQI/P+9y1EtXLurq6dPLkSSUnJ8vn80U8FwqFlJOTo8bGRqWkpBhNaI/zcBnn4TLOw2Wch8v6wnlwzqm1tVXZ2dkaMqTnd3r63BXQkCFDNHr06M/dJyUlZVC/wD7FebiM83AZ5+EyzsNl1ufh8658PsWHEAAAJggQAMBEvwqQ3+/X2rVr5ff7rUcxxXm4jPNwGefhMs7DZf3pPPS5DyEAAAaHfnUFBAAYOAgQAMAEAQIAmCBAAAAT/SZAmzZt0pe//GXdcMMNys/P129/+1vrkXrds88+K5/PF7FNnDjReqy4279/v+bOnavs7Gz5fD7t2rUr4nnnnNasWaOsrCwNGzZMRUVFOnr0qM2wcXSt87B06dKrXh9z5syxGTZOysvLNW3aNCUnJys9PV3z589XXV1dxD4XLlxQaWmpRo4cqZtuukkLFy5Uc3Oz0cTx8UXOQ2Fh4VWvh8cee8xo4u71iwC9/vrrWr16tdauXasPPvhAeXl5Ki4u1unTp61H63V33HGHTp06Fd7ef/9965Hirq2tTXl5edq0aVO3z2/YsEEvvviiNm/erAMHDujGG29UcXGxLly40MuTxte1zoMkzZkzJ+L18dprr/XihPFXVVWl0tJS1dTUaO/evero6NDs2bPV1tYW3mfVqlV66623tGPHDlVVVenkyZNasGCB4dSx90XOgyQtW7Ys4vWwYcMGo4l74PqB6dOnu9LS0vDXnZ2dLjs725WXlxtO1fvWrl3r8vLyrMcwJcnt3Lkz/HVXV5fLzMx0zz33XPixlpYW5/f73WuvvWYwYe+48jw459ySJUvcvHnzTOaxcvr0aSfJVVVVOecu/79PTEx0O3bsCO/z0UcfOUmuurraasy4u/I8OOfcvffe67773e/aDfUF9PkroIsXL6q2tlZFRUXhx4YMGaKioiJVV1cbTmbj6NGjys7O1rhx4/TQQw/p+PHj1iOZamhoUFNTU8TrIxAIKD8/f1C+PiorK5Wenq7bbrtNy5cv15kzZ6xHiqtgMChJSk1NlSTV1taqo6Mj4vUwceJEjRkzZkC/Hq48D5969dVXlZaWpkmTJqmsrEznzp2zGK9Hfe5mpFf65JNP1NnZqYyMjIjHMzIy9Kc//cloKhv5+fnaunWrbrvtNp06dUrr1q3TPffcoyNHjig5Odl6PBNNTU2S1O3r49PnBos5c+ZowYIFys3N1bFjx/SDH/xAJSUlqq6uVkJCgvV4MdfV1aWVK1dqxowZmjRpkqTLr4ekpCSNGDEiYt+B/Hro7jxI0oMPPqixY8cqOztbhw8f1lNPPaW6ujq9+eabhtNG6vMBwt+UlJSEfz1lyhTl5+dr7NixeuONN/TII48YToa+YPHixeFfT548WVOmTNH48eNVWVmpWbNmGU4WH6WlpTpy5MigeB/08/R0Hh599NHwrydPnqysrCzNmjVLx44d0/jx43t7zG71+b+CS0tLU0JCwlWfYmlublZmZqbRVH3DiBEjNGHCBNXX11uPYubT1wCvj6uNGzdOaWlpA/L1sWLFCr399tt67733In58S2Zmpi5evKiWlpaI/Qfq66Gn89Cd/Px8SepTr4c+H6CkpCRNnTpVFRUV4ce6urpUUVGhgoICw8nsnT17VseOHVNWVpb1KGZyc3OVmZkZ8foIhUI6cODAoH99nDhxQmfOnBlQrw/nnFasWKGdO3dq3759ys3NjXh+6tSpSkxMjHg91NXV6fjx4wPq9XCt89CdQ4cOSVLfej1Yfwrii9i+fbvz+/1u69at7o9//KN79NFH3YgRI1xTU5P1aL3qe9/7nqusrHQNDQ3u17/+tSsqKnJpaWnu9OnT1qPFVWtrq/vwww/dhx9+6CS5559/3n344YfuL3/5i3POuR//+MduxIgRbvfu3e7w4cNu3rx5Ljc3150/f9548tj6vPPQ2trqnnjiCVddXe0aGhrcu+++67761a+6W2+91V24cMF69JhZvny5CwQCrrKy0p06dSq8nTt3LrzPY4895saMGeP27dvnDh486AoKClxBQYHh1LF3rfNQX1/v1q9f7w4ePOgaGhrc7t273bhx49zMmTONJ4/ULwLknHMbN250Y8aMcUlJSW769OmupqbGeqRet2jRIpeVleWSkpLczTff7BYtWuTq6+utx4q79957z0m6aluyZIlz7vJHsZ955hmXkZHh/H6/mzVrlqurq7MdOg4+7zycO3fOzZ49240aNcolJia6sWPHumXLlg24P6R1998vyW3ZsiW8z/nz5913vvMd96UvfckNHz7c3X///e7UqVN2Q8fBtc7D8ePH3cyZM11qaqrz+/3ulltucd///vddMBi0HfwK/DgGAICJPv8eEABgYCJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPw/KifbaknT53AAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(random_example.reshape(1,28,28))\n",
        "print(f'Actual: {training_data[1][random_index][0]}')\n",
        "print(f'Model Prediction: {np.argmax(prediction)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62tQZJWsJWns",
        "outputId": "86a726f6-7beb-4479-ec25-85812a9e25f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "Actual: 2\n",
            "Model Prediction: 2\n"
          ]
        }
      ]
    }
  ]
}